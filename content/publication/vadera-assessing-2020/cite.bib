@article{vadera_assessing_2020,
 abstract = {In this paper, we consider the problem of assessing the ad-versarial robustness of deep neural network models under both Markov chain Monte Carlo (MCMC) and Bayesian Dark Knowledge (BDK) inference approximations. We characterize the robustness of each method to two types of adversarial attacks: the fast gradient sign method (FGSM) and projected gradient descent (PGD). We show that full MCMC-based inference has excellent robustness, significantly outperforming standard point estimation-based learning. On the other hand, BDK provides marginal improvements. As an additional contribution , we present a storage-efficient approach to computing adversarial examples for large Monte Carlo ensembles using both the FGSM and PGD attacks.},
 author = {Vadera, Meet P and Narayan Shukla, Satya and Jalaian, Brian and Marlin, Benjamin M },
 copyright = {All rights reserved},
 file = {Attachment:/Users/bjalaian/Zotero/storage/TFW5Z2TS/Vadera et al. - Unknown - Assessing the Adversarial Robustness of Monte Carlo and Distillation Methods for Deep Bayesian Neural Netwo(2).pdf:application/pdf},
 journal = {arXiv preprint arXiv:2002.02842},
 note = {_eprint: 2002.02842v1},
 title = {Assessing the Adversarial Robustness of Monte Carlo and Distillation Methods for Deep Bayesian Neural Network Classification},
 year = {2020}
}

